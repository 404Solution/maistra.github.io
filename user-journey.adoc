= User Journey for Istio/Jaeger

This document describes the steps required to install a local Istio Openshift instance, necessary prerequisites, and describes how the your can experiment with Istio enabled missions using the launcher.

== Flows description

The Fabric8 Launcher provides two workflows to play with an Istio mission (zip vs. git flow), and this document will apply to either - described below:

. *`Zip flow`:* Selected mission is downloaded from the web site as a zip archive and extracted to the local filesystem.
. *`Git flow`:* Selected mission is saved to a GitHub repository/account, and an Istio enabled application is created in a local Openshift instance.

== Prerequisites
. At least 6 Gb of free RAM, 4 CPUs
. *Install Java JDK 8* (necessary only for `Zip flow` and boosters using Fabric8 Maven Plugin)
.. http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html[JDK 8]
.. http://maven.apache.org/download.cgi[Maven 3.5]
. *Set up Git SCM / GitHub account*
.. Install https://git-scm.com/downloads[Git SCM client]
.. Set up a https://github.com[GitHub account]
.. Configure a GitHub https://github.com/fabric8-launcher/launcher-documentation/blob/master/docs/topics/proc_creating-a-github-personal-access-token.adoc[API access token].
. *Configure certificates for Red Hat Container Image Registry*
... RHEL - Certificates are already installed. No action is required.
... Fedora/CentOS/VM - it is required to have this package installed in order to install Red Hat certificate. This allows the docker daemon to access the Red Hat Container Image Registry
+
----
yum install -y ansible python-rhsm-certificates
----
... Ubuntu/Debian with native Hypervisor, you will need to take a few extra steps:
+
----
wget https://rpmfind.net/linux/fedora/linux/updates/27/x86_64/Packages/p/python-rhsm-certificates-1.20.2-1.fc27.x86_64.rpm
sudo alien python-rhsm-certificates-1.20.2-1.fc27.x86_64.rpm
sudo dpkg -i python-rhsm-certificates_1.20.2-2_amd64.deb
----
. *Install a docker daemon and configure it*
.. CentOS/Fedora
... Install Atomic docker package (if not yet done):
+
----
yum install docker
systemctl enable docker
systemctl start docker
----
... Edit the file “/etc/docker/daemon.json” to specify the IP Address and the  PORT on which the server can be access from the HOST:
+
----
{
"insecure-registries" : [ "172.30.0.0/16" ],
"hosts" : [ "unix://", "tcp://0.0.0.0:2376" ]
}
----
... Define the DOCKER_HOST env var within the HOST machine
+
----
export DOCKER_HOST=tcp://ETHERNET_IP_ADDRESS:2376
----
.. Ubuntu with at least 6 Gb of RAM, 4 CPUs :
... Follow installation instructions for Docker CE at https://docs.docker.com/install/linux/docker-ce/ubuntu/
... Create the following file (and directories, if necessary)
+
./etc/systemd/system/docker.service.d/overlay.conf
----
[Service]
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --label provider=generic --insecure-registry 172.30.0.0/16
Environment=
----
... Run the following commands
+
----
sudo systemctl daemon-reload
sudo systemctl restart docker
----
.. Mac OSX
... Configure a CentOS VM using as Hypervisor virtualbox or xhyve. The system will require at least 6 Gb of RAM and 4 CPUs - Process has been documented here: https://gist.github.com/cmoulliard/039e85e17ee99ad8c9e25b975d3f3a8a
... Next, the docker daemon and Red Hat certificates should be installed using the same instructions for CentOS/Fedora using `yum` or `dnf`.
. *Determine the docker daemon `ETHERNET_IP_ADDRESS`*
+
The ETHERNET_IP_ADDRESS, as defined within this doc, is the ethernet IP accessible from the host to the VM. This address could be part of a private network created behind the host and the guest = vm. It can also be the address of the docker daemon network adapter if running natively.
+
TIP: If, the host address of your MacOS, Window or Linux desktop is “192.168.99.20” and the Centos Linux VM running the docker daemon is “192.168.99.50”, then, in this case, the ETHERNET_IP_ADDRESS is “192.168.99.50”
+
Refer to https://dzone.com/articles/discovering-dockers-ip-address[Discovering docker daemon’s IP Address] if you need more guidance in determining the correct IP address in a native installation.

== Use case scenario : `git flow`
. Install istio `oc` client and adds it to your path.
+
TIP: Make sure you have the latest `istiooc` version by going to https://github.com/openshift-istio/origin/releases - the following instructions assume version `*-alpha7`
+
----
mkdir istiooc && cd istiooc

#osx
wget -O oc https://github.com/openshift-istio/origin/releases/download/istio-3.9-0.7.1-alpha7/istiooc_darwin
chmod +x oc

#linux
wget -O oc https://github.com/openshift-istio/origin/releases/download/istio-3.9-0.7.1-alpha7/istiooc_linux
chmod +x oc

# Add the client to your path
export PATH=$(pwd):$PATH #or add to PATH variable in profile
----
. Ensure that the latest origin-ansible docker image has been downloaded, just in case it was updated recently:
+
----
docker pull openshiftistio/origin-ansible:0.7.1
----
. Start the cluster using `--istio` and `--launcher-*` parameters
+
These install Istio and the Red Hat Launcher into the OpenShift cluster, respectively. This is where you will need your GitHub username and API Access Token. Click https://github.com/settings/tokens[here] to generate your GitHub token.
+
----
oc cluster up \
   --public-hostname=ETHERNET_IP_ADDRESS \
   --istio \
   --launcher \
   --launcher-catalog-git-branch=GIT_REF_BOOSTERS_REPO \
   --launcher-catalog-git-repo=GIT_HUB_BOOSTERS_REPO \
   --launcher-openshift-user=OPENSHIFT_ADMIN_USER \
   --launcher-openshift-password=OPENSHIFT_ADMIN_PWD \
   --launcher-github-username=GITHUB_USER \
   --launcher-github-token=GITHUB_TOKEN
----
+
You can also use the sensible defaults we have in place and provide only the following info:
+
----
oc cluster up \
   --public-hostname=ETHERNET_IP_ADDRESS \
   --istio \
   --launcher \
   --launcher-openshift-user=OPENSHIFT_ADMIN_USER \
   --launcher-openshift-password=OPENSHIFT_ADMIN_PWD \
   --launcher-github-username=GITHUB_USER \
   --launcher-github-token=GITHUB_TOKEN
----
. Wait until the “launcher-backend” and “launcher-fronted” pods have been started
+
----
oc get pods -n devex -w
NAME                          READY     STATUS    RESTARTS   AGE
configmapcontroller-1-vh78r   1/1       Running   0          1m
launcher-backend-2-vb4vt      1/1       Running   0          1m
launcher-frontend-2-bc7n2     1/1       Running   0          1m
----
. Log into the OpenShift console:
.. https://ETHERNET_IP_ADDRESS:8443
. Open the launcher UI URL, which is one of the featured applications.
.. http://launcher-devex.ETHERNET_IP_ADDRESS.nip.io:8843/
+
IMPORTANT: Do NOT use HTTPS - nothing is listening there!
. Click the “Launch your Project” button
. Select the deployment type - "Use OpenShift online", click 'Next'
. Select an Istio mission, click 'Next'
. Select a runtime, click 'Next' (see video for the Routing Testing Booster using Spring Boot - https://www.youtube.com/watch?v=hsd6ezE2tpg)
. Set project name
+
NOTE: By convention it will be used as the name of the OpenShift project and repository created in the specified GitHub account
. Finish launcher workflow, then:
..  Click the link to open booster README end of Launcher wizard
..  Click the link to open booster UI at end of Launcher wizard
. Follow the booster tutorial workflow as defined in the README.


== Use case scenario : `zip flow`
. Follows steps 1-7 of `git flow` (Stop after "Launch your Project")
. After step 7, select 'Download as ZIP', then complete remaining steps (skip 12b, "Open booster UI").
. At the end of the workflow, click "Download" link.
. When download is complete, unzips the file, then runs instructions from the booster documentation:
.. https://github.com/snowdrop/spring-boot-istio-ab-testing-booster/blob/master/README.md
